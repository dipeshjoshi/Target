# HDFS config settings

nameNode=hdfs://bigredns
oozieURL=http://bigredoozie.target.com:11000/oozie
jobTracker=rpc://d-3zjtk02.target.com:8050
metastore_uri=thrift://d-3zktk02.target.com:9083,thrift://d-3zksk02.target.com:9083
metastore_principal=hive/d-3zksk02.target.com@BIGRED.TARGET.COM
oozie.use.system.libpath=true
queueName=analysis
ENV=stg
WF_DIR=${nameNode}/common/demandforecasting/workflows/${ENV}/dfe-arimax-wf/current
WF_PATH=${WF_DIR}/dfe-arimax-training.xml
DATA_DIR=/common/demandforecasting/data


# Workflow application path
oozie.coord.application.path=${WF_DIR}/dfe-arimax-coordinator.xml

# Job name
JOB_NAME=dfe-arimax-train-${ENV}

# Coordinator Properties
freqDays=1
startTime=2018-01-15T09:00Z
endTime=2027-11-30T00:00Z
coordinatorTimeout=-1
concurrency=1
appWorkflowPath=${WF_PATH}

# Input Parameters
DFE_WF_MONITOR_DB=${ENV}_dfe_wf_monitor
DFE_WF_MONITOR_DB_DIR=${nameNode}${DATA_DIR}/${DFE_WF_MONITOR_DB}.db

# Source Tables
SLS_HIST_DB=prd_dfe_slshist

HIVE_FCST_DB=${ENV}_arimax_train
HIVE_FCST_DB_DIR=${nameNode}${DATA_DIR}/training/${HIVE_FCST_DB}.db

#Workflow Specific Parameters
TRAIN_INPUT_TABLE=train_input_table
TRAIN_INPUT_DIR=${HIVE_FCST_DB_DIR}/${TRAIN_INPUT_TABLE}
TRAIN_OUTPUT_TABLE=arimax_train_output
TRAIN_OUTPUT_DIR=${HIVE_FCST_DB_DIR}/${TRAIN_OUTPUT_TABLE}
MODEL_PATH=${DATA_DIR}/arimax_models
MODEL_DIR=${DATA_DIR}/training/${HIVE_FCST_DB}.db/modelhub
REL_DATE=001


SALES_HISTORY_TABLE=${SLS_HIST_DB}.store_sales_history_chain_week
CALENDAR_BTS_TABLE=${SLS_HIST_DB}.btc_calendar
CALENDAR_CHRISTMAS_TABLE=${SLS_HIST_DB}.christmas_calendar


# Final output properties
MODEL_NAME=item-demand-forecasting-arimax
STRATEGY_NAME=item-demand-forecasting-arimax
ALGO_NAME=item-demand-forecasting-arimax
ALGO_VERSION=0.1
DONE_FLAG=dfe-slshistprep-v3-storehistory-wf.done


#Email notifications
EMAIL_LIST_REPORT=SIA-EDABI-DSE-IDFCT-RPT@Target.com
EMAIL_LIST=SIA-EDABI-DSE-IDFCT-OPS@Target.com

# oozie job -config=dfe-arimax-training-stg.properties -run -oozie http://bigredoozie.target.com:11000/oozie
